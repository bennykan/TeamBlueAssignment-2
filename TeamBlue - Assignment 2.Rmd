---
title: "Clustering Algorithm for Unupervised Learning - Credit Card Client Anomaly Analysis"
author: "Tyler Blakeley, Benjamin Kan, Mohammad Islam, Avijeet Singh"
date: "October 29 2018"
output:
  html_document:
    fig_height: 4.5
    fig_width: 7
    highlight: tango
    number_sections: yes
    theme: readable
    toc: yes
  pdf_document:
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
```
# Business Understanding
We work at the Retail Credit Risk Analytics department at the Bank of Taiwan. Recently, there have been increasing credit card debt defaults in our bank. Senior Management would like our department to develop a machine learning algorithm to find anomalies in the data that we hope will show early warning signs of default. This will allow the Retail Credit Risk and Collections departments to act early by reducing these cleints' credit card limits to minimize the losses. We would also like to find out which demographics are in the anomaly group which would indicate high susceptiblility of defaults. The Management instructed us to use data from the third parties to build the algorithms as proof-of-concepts before we use our own data. They would also like us to build a user-friendly app to allow them to load in the dataset and identify clients that are in the anomaly group which may indicate high risk of defaulting on their credit card debts.        

# Data Understanding

## Data Source and Collection
We sourced the third party credit card data from Kaggle (https://www.kaggle.com/uciml/default-of-credit-card-clients-dataset). This dataset contains information on default payments, demographic factors, credit data, history of payment, and bill statements of credit card clients in Taiwan from April 2005 to September 2005. As mentioned above, the goal is to identify a group of customers who have high default risks. 

## Data Description
In the dataset, there are 25 variables:

Variable Name              | Description
---------------------------|--------------------------------------------------------------------------------
ID                         | ID of each client
LIMIT_BAL                  | Amount of given credit in NT dollars (includes individual and                                               | family/supplementary credit
SEX                        | Gender (1=male, 2=female)
EDUCATION                  | (1=graduate school, 2=university, 3=high school, 4=others, 5=unknown, 6=unknown)
MARRIAGE                   | Marital status (1=married, 2=single, 3=others)
AGE                        | Age in years
PAY_0                      | Repayment status in September, 2005 (-1=pay duly, 1=payment delay for one month,                            | 2=payment delay for two months, ... 8=payment delay for eight months, 9=payment                             | delay fornine months and above)                 
PAY_2                      | Repayment status in August, 2005 (scale same as above)
PAY_3                      | Repayment status in July, 2005 (scale same as above)
PAY_4                      | Repayment status in June, 2005 (scale same as above)
PAY_5                      | Repayment status in May, 2005 (scale same as above)
PAY_6                      | Repayment status in April, 2005 (scale same as above)
BILL_AMT1                  | Amount of bill statement in September, 2005 (NT dollar)
BILL_AMT2                  | Amount of bill statement in August, 2005 (NT dollar)
BILL_AMT3                  | Amount of bill statement in July, 2005 (NT dollar)
BILL_AMT4                  | Amount of bill statement in June, 2005 (NT dollar)
BILL_AMT5                  | Amount of bill statement in May, 2005 (NT dollar)
BILL_AMT6                  | Amount of bill statement in April, 2005 (NT dollar)
PAY_AMT1                   | Amount of previous payment in September, 2005 (NT dollar)
PAY_AMT2                   | Amount of previous payment in August, 2005 (NT dollar)
PAY_AMT3                   | Amount of previous payment in July, 2005 (NT dollar)
PAY_AMT4                   | Amount of previous payment in June, 2005 (NT dollar)
PAY_AMT5                   | Amount of previous payment in May, 2005 (NT dollar)
PAY_AMT6                   | Amount of previous payment in April, 2005 (NT dollar)
default.payment.next.month | Default payment (1=yes, 0=no)

## Data Exploration

### Load Packages
```{r, message=FALSE,warning=FALSE}
#import packages;
library(dplyr)
library(reshape2)
library(ggplot2)
library(Hmisc)
library(corrplot)
library(mice)
library(VIM)
library(pROC)
library(caret)
library(corrgram)
library(GGally)
library(ggthemes) 
library(DMwR)
library(gridExtra)
library(rattle)
library(readxl)
library(cluster)
```
### Load Datasets
Now that the packages are loaded,we can load in the dataset.

```{r, message=FALSE}
data <- read.csv("default of credit card clients.csv", header = TRUE, na= 'NA')
```

Now lets look at the structure of the data.

```{r, message=FALSE}
str(data)
```

We've got a sense of our variables, their class type, and the first few observations of each. We know we're working with 920 observations of 14 variables.

### Feature Engineering

Upon initial inspection of the data, we found that the data convention for the TARGET attribute is inconsistent among the 4 datasets. Both Switzerland and VA datasets have the heart disease dignosis target variable with the values of 0, 1, 2, 3 and 4 instead of the values of 0 or 1. Here we will make the data format consistent with the data definition described above (i.e 0: < 50% diameter narrowing; 1: > 50% diameter narrowing). So we made the following adjustments on the TARGET attribute:

```{r, message=FALSE}
# original target variable distributions
table(full_data$TARGET)
full_data$TARGET <- ifelse(full_data$TARGET>=1,1,full_data$TARGET)
# final target variable distributions
table(full_data$TARGET)
```

Also we reckon that converting the variable SEX into M & F would be easier to understand instead of "1" and "0" respectively, so we replace them.

```{r, message=FALSE,warning=FALSE}
full_data$SEX<-ifelse(full_data$SEX==1,"M","F")
```

Lastly,we can see that the attributes('SEX','CP','FBS','RESTECG','EXANG','SLOPE','CA','THAL','TARGET') are all categorical variables so we convert them into factors

```{r, message=FALSE,warning=FALSE}
factor_VARS <- c('SEX','CP','FBS','RESTECG','EXANG','SLOPE','CA','THAL','TARGET')
full_data[factor_VARS]<- lapply(full_data[factor_VARS],function(x) as.factor(x))
```

Before we dig into data exploration, let us see what our data looks like now after all the changes.

```{r, message=FALSE,warning=FALSE}
str(full_data)
```

###Data Analysis
Now we explore the data. We can divide it into two categories:
* Categorical Features
* Numerical Features

####Categorical Features
Let us visualize the categorical data.

#####SEX
```{r, message=FALSE,warning=FALSE}
attach(full_data)
freq_tbl_sex=table(SEX)
head(freq_tbl_sex)
barplot(freq_tbl_sex,xlab = "SEX", ylab = "Number of Patients",main = "Bar chart of Gender of Patients ",col=c("pink","navyblue"))
```

Clearly the number of male patients in this dataset is more than the female patients.
Let us now see the relationship between the gender and our target.

```{r, message=FALSE,warning=FALSE}
freq_xtab_sex=xtabs(~SEX+TARGET)
barplot(freq_xtab_sex, legend=rownames(freq_xtab_sex), ylab="Number of People", xlab="Target", col=c("pink","navyblue"), beside=T, las=1)
```

The graph above shows that higher proportion of males was diagnosed with the heart disease.

#####CP(Chest Pain)
```{r, message=FALSE,warning=FALSE}
freq_tbl_CP=table(CP)
barplot(freq_tbl_CP,xlab = "Chest Pain Type", ylab = "Number of Patients",main = "Bar chart of Chest Pain",col=c("green","yellow","purple","red"))
```

From the plot it is evident that there is more number of patients with CP Type 4 (Asymptomatic).

Now lets look at CP against our Target Variable.

```{r, message=FALSE,warning=FALSE}
freq_xtab_CP=xtabs(~CP+TARGET)
barplot(freq_xtab_CP, legend=rownames(freq_xtab_CP), ylab="Patients", xlab="Target", col=c("green","yellow","purple","red"), beside=T, las=1)
```

From the plot above, we can see that patients with CP (Chest Paint Type) 4 is more prone to have heart disease.

#####FBS(Fasting Blood Sugar)
We have more number of patients with low blood sugar i.e. <120mg/L as we can see from the following plot.

```{r, message=FALSE,warning=FALSE}
freq_tbl_FBS=table(FBS)
barplot(freq_tbl_FBS,xlab = "Fasting Blood Sugar(FBS)", ylab = "Number of Patients",main = "Bar chart of FBS",col=c("purple","yellow"))

```

Now lets plot it with respect to our target variable.

```{r, message=FALSE,warning=FALSE}
freq_xtab_FBS=xtabs(~FBS+TARGET)
barplot(freq_xtab_FBS, legend=rownames(freq_xtab_FBS), ylab="Number of People", xlab="Target", col=c("purple","yellow"), beside=T, las=1)
```

The plot did not change much when the data was divided based on the presence of the heart disease although patients diagnosed with heart disease exhibited a slighlty higher level of blood sugar.

#####Rest ECG

```{r, message=FALSE,warning=FALSE}
freq_tbl_RESTECG=table(RESTECG)
barplot(freq_tbl_RESTECG,xlab = "RESTECG", ylab = "Number of Patients",main = "Bar chart of RESTECG",col=c("green","purple","yellow"))
```

0-Normal
1-abnormal
2-Hypertrophy

Now lets compare with our TARGET

```{r, message=FALSE,warning=FALSE}
freq_xtab_RESTECG=xtabs(~RESTECG+TARGET)
barplot(freq_xtab_RESTECG, legend=rownames(freq_xtab_RESTECG), ylab="Number of People", xlab="Target", col=c("green","purple","yellow"), beside=T, las=1)
```

Most patients exhibited normal RESTECG results. However, a higher proportion of diseased patients had abnormal ST wave patterns suggesting that this feature may contribute some predictive power.

#####EXANG - Exercise Induced Angina.

We can see from the following plot that there is more noumber of individuals who do not have exercise induced angina.

```{r, message=FALSE,warning=FALSE}
freq_tbl_EXANG=table(EXANG)
barplot(freq_tbl_EXANG,xlab = "EXANG", ylab = "Number of Patients",main = "Bar chart of EXANG",col=c("green","purple","yellow"))
```

Let us compare with our TARGET.

```{r, message=FALSE,warning=FALSE}
freq_xtab_EXANG=xtabs(~EXANG+TARGET)
barplot(freq_xtab_EXANG, legend=rownames(freq_xtab_EXANG), ylab="Number of People", xlab="Target", col=c("green","purple"), beside=T, las=1)
```
In the number of individuals diagnosed with the heart disease most of them had exercise induced angina.
This is a strong predictive attribute.

We will stop here as the remaining factor attributes have a lot of missing values.

####Numeric Features

#####Age

Let us plot a histogram to see the distribution of ages.

```{r, message=FALSE,warning=FALSE}
hist(full_data$AGE,main = "Distribution of Age",xlab = "Age",ylab = "Number of People")
```

Now lets see the age distribution according to our Target.

```{r, message=FALSE,warning=FALSE}
ggplot(full_data, aes(AGE, fill = TARGET)) + 
  geom_histogram() + 
  theme_few()
```

We can see that the individuals diagnosed with heart disease have a slightly higher age.

#####TRSETBPS(Resting Blood Pressure (in mm Hg on admission to the hospital))

Let us check the distribution of TRESTBPS

```{r, message=FALSE,warning=FALSE}
hist(full_data$TRESTBPS,main = "Distribution of TRESTBPS",xlab = "TRESTBPS",ylab = "Number of People")
```
```{r, message=FALSE,warning=FALSE}
ggplot(full_data, aes(TRESTBPS, fill = TARGET)) + 
  geom_histogram() + 
  theme_few()
```

We can see higher the TRESTBPS, higher are the chances of getting diagnosed with the heart disease.
Now let us check the outliers in TRESTBPS.

```{r, message=FALSE,warning=FALSE}
boxplot(full_data$TRESTBPS,ylab='Resting blood pressure',main='Boxplot distribution of TRESTBPS')
```

#####CHOL(Serum Cholestoral in mg/dl)

Let us check the distribution of TRESTBPS VS TARGET

```{r, message=FALSE,warning=FALSE}
ggplot(full_data, aes(CHOL, fill = TARGET)) + 
  geom_histogram() + 
  theme_few()
```

Box plot for cholestrol.

```{r, message=FALSE,warning=FALSE}
boxplot(full_data$CHOL,ylab='Cholestrol',main='Boxplot distribution of CHOL')
```

#####THALACH(Maximum Heart Rate Achieved)

```{r, message=FALSE,warning=FALSE}
ggplot(full_data, aes(THALACH, fill = TARGET)) + 
  geom_histogram() + 
  theme_few()
```

This shows that the maximum heart rate was higher for the non-diseased individuals as compared to the diseased individuals.

Lets check for outliers in this group.

```{r, message=FALSE,warning=FALSE}
boxplot(full_data$THALACH,ylab='Maximum heart rate',main='Boxplot distribution of THALACH')
```

#####OLDPEAK(ST Depression Induced by Exercise Relative to Rest)

Let us check the distribution of OLDPEAK VS TARGET

```{r, message=FALSE,warning=FALSE}
ggplot(full_data, aes(OLDPEAK, fill = TARGET)) + 
  geom_histogram() + 
  theme_few()
```

We can see that higher the value for OLDPEAK there are more chances of the individual to be diagnosed with heart disease.

Now lets check for outliers.

```{r, message=FALSE,warning=FALSE}
boxplot(full_data$OLDPEAK,ylab='ST Depression Induced by Exercise Relative to Rest',main='Boxplot distribution of OLDPEAK')
```

We would like to find out if there are any relationships among the numerical variables. We are using the GGPAIRS plot:

```{r, message=FALSE,warning=FALSE}
ggpairs(full_data[, !names(full_data)%in% factor_VARS])

```

Interestingly, the correlations among the numerical variables are not as strong. And this shows in the scatter plots.

## Data Quality Verification

### Missing Data

First let us summarize the data and see how it looks like.

```{r, message=FALSE,warning=FALSE}
summary(full_data)
```

We now visualize the missing data through a histogram.

```{r, message=FALSE,warning=FALSE}
aggr_plot = aggr(full_data, col=c('navyblue','red'), numbers=TRUE, sortVars=TRUE, labels=names(full_data), cex.axis=.7, gap=3, ylab=c("Histogram of missing data","Pattern"))
```

As we analyze all the variables, we found some attribute with substantial missing values.  There was a couple of variables that caught our attention where varable **CA**  with `r round(sum(is.na(full_data$CA)) / nrow(full_data)*100)` % missing data, **SLOPE** with `r round(sum(is.na(full_data$SLOPE)) / nrow(full_data)*100)` % missing data and **THAL** with `r round(sum(is.na(full_data$THAL)) / nrow(full_data)*100)` % missing data.  

Other attributes have missing data as well but the issue is not as severe. We will deal with these under the Data Preparation section separately.

### Outliers

Based on the boxplots above, we found that there are zero values for the cholesterol level and resting blood pressure. These observations are not physically possible they don't make sense. We will treat these under the Data Preparation section. 

# Data Preparation

Now that we are done with data exploration we can move on to data preparation.

## Attributes with High Percentage of Missing Data

As mentioned above, there are three varibales which have a high percent of missing data. We chose to remove them so that they won't distort our prediction model.

```{r, message=FALSE,warning=FALSE} 
full_data_truncated<-as.data.frame(full_data[, !names(full_data) %in% c("THAL","CA","SLOPE")])
summary(full_data_truncated)
``` 

## Zero Values for Cholesteral and Resting Blood Pressure Measurements

We assume that zero cholesteral and resting blood pressure values are erroneous so we will treat them as missing:

```{r, message=FALSE,warning=FALSE}
full_data_truncated$CHOL[full_data_truncated$CHOL == 0] <- NA
full_data_truncated$TRESTBPS[full_data_truncated$TRESTBPS == 0] <- NA
```




We can see that all the missing data has now been imputed and the correlations between the variables have not been shifted due to the imputed data.

# Modelling

## Select Modelling Technique

We chose to start with a k means clustering alorgirthm as most of our data was numeric and we were able to easily encode the categorical variables to make them numeric.  

## Encode Data

```{r, message=FALSE,warning=FALSE}
set.seed(456292)

#assume AVI will remove this but keeping it for you guys to test
#remove default column, create unlabelled dataset and ID Column
data <- data[,!colnames(data) %in% c("default.payment.next.month")]


#factor categorical variables
factor_VARS <- c('SEX','EDUCATION','MARRIAGE','PAY_0','PAY_2','PAY_3','PAY_4','PAY_5','PAY_6')

data[factor_VARS]<- lapply(data[factor_VARS],function(x) as.factor(x))


#encod categorical columns
dummies_model <- dummyVars(ï..ID ~ ., data=data)

# Create the dummy variables using predict. The Y variable (ï..ID) will not be present in encod
encod <- predict(dummies_model, newdata = data)

# # Convert to dataframe
data_encoded <- data.frame(encod)

# # See the structure of the new dataset
str(data_encoded)


```


## Find Optimal number of Clusters (K)

To find the optimal number of clusters we used the Elbow method. The elbow method finds the optinal K value by considering the percentage of variance explained by each cluster.

```{r, message=FALSE,warning=FALSE}
#Find Optimal K using Elbow method

df <- sample_n(data_encoded,10000)

wssplot <- function(data, nc=15, seed=1234){
  wss <- (nrow(data)-1)*sum(apply(data,2,var))
  for (i in 2:nc){
    set.seed(seed)
    wss[i] <- sum(kmeans(data, centers=i)$withinss)}
  plot(1:nc, wss, type="b", xlab="Number of Clusters",
       ylab="Within groups sum of squares")}

wssplot(df, nc=10) 



```

Based on the Elbow method, we found the optinal number to be 6


## Build K Means Model 
```{r, message=FALSE,warning=FALSE}

kmeans.result <- kmeans(df, centers=6)

```

Explain K Means Models ......


## Assess Clusters

```{r, message=FALSE,warning=FALSE}


#Describe Clusters

#ClusterSize
kmeans.result$size

#Cluster Center Attributes 
kmeans.result$centers


#Vizualize Clusters
par(mfrow=c(3,2))
pie(colSums(df[kmeans.result$cluster==1,]),cex=0.5)

pie(colSums(df[kmeans.result$cluster==2,]),cex=0.5)

pie(colSums(df[kmeans.result$cluster==3,]),cex=0.5)
pie(colSums(df[kmeans.result$cluster==4,]),cex=0.5)
pie(colSums(df[kmeans.result$cluster==5,]),cex=0.5)
pie(colSums(df[kmeans.result$cluster==6,]),cex=0.5)

```


### Visualize Model with PCA

We will use Principle Componet Analysis (PCA) to help us Visualize our clusters.  PCA works by reducing dimensoinality of the data. We want to reduce the dimensionality to 2d because it will allow us to graph the clusters. PCA 
creates new columns that are linearly uncorrelated variables, and sorts thems in descending where PC1 will account for the highest variability of the data, and PC2 will be seocnd most and so on.

```{r, message=FALSE,warning=FALSE}
df_pca <- prcomp(df)
df_out <- as.data.frame(df_pca$x)

p<-ggplot(df_out,aes(x=PC1,y=PC2,color = as.factor(kmeans.result$cluster ) ))
theme<-theme(panel.background = element_blank(),panel.border=element_rect(fill=NA),panel.grid.major = element_blank(),panel.grid.minor = element_blank(),strip.background=element_blank(),axis.text.x=element_text(colour="black"),axis.text.y=element_text(colour="black"),axis.ticks=element_line(colour="black"),plot.margin=unit(c(1,1,1,1),"line"))
percentage <- round(df_pca$sdev / sum(df_pca$sdev) * 100, 2)
percentage <- paste( colnames(df_out), "(", paste( as.character(percentage), "%", ")", sep="") )

p<-p+geom_point()+theme+xlab(percentage[1]) + ylab(percentage[2])

p

```

Looking at the vizualized data we can see the clusters are well formed and there is minimal overlap, the dclusters are almost fully homogeneous.


##Find Anomalies (Outliers)



###Anomaly Detection using K Means

```{r, message=FALSE, warning=FALSE}

#Find the Center of each cluster
centers <- kmeans.result$centers[kmeans.result$cluster, ]  

# Calculate distance each point is from the center of the cluster
distances <- sqrt(rowSums((df - centers)^2))
# Take the top 20 fartherest points from the cluster center
outliers <- order(distances, decreasing=T)[1:20]

#Plot Outliers
p<-p + geom_point(data=df_out[outliers,],aes(x=PC1,y=PC2), colour="red", size=4)+ggtitle("PCA 6 Means Cluster with Outliers")

p



```



###Anomaly Detection using Local Outlier Factor


Another way to find outlier in unsupervised learning is by using the Local outlier
Facotr alogorithm.  This alogrithm is similar to the previous one we used but differs
by comparing local density,where locality is based on the k nearest neighbours.  The LOF
allows us to identify outliers in a data set tha would not be outliers in another area of the data set.


```{r, message=FALSE,warning=FALSE}

#run LOF Model takes awhile 5 to 10 minutes
outlier.scores <- lofactor(df,k=30)

#Plotdensity of Outliers
plot(density(outlier.scores))


#Plot outliers from LOF
outliers_lof <- order(outlier.scores, decreasing=T)[1:20]


p_lof<-ggplot(df_out,aes(x=PC1,y=PC2,color = as.factor(kmeans.result$cluster ) ))+geom_point()+theme+xlab(percentage[1]) + ylab(percentage[2]) + geom_point(data=df_out[outliers_lof,],aes(x=PC1,y=PC2), colour="red", size=3)+ggtitle("PCA LOF Outliers")


#compare K means outlier to LOF
grid.arrange(p, p_lof, nrow = 2,ncol = 1)



```







### Look at individual outliers

```{r, message=FALSE,warning=FALSE}


```

The Random Forest with 500 trees and mtry of`r bestmtry$mtry` had a overall accuracy of  `r round(RF_confus$overall[1]*100,2)` compared to the decision tree model of `r round(confus$overall[1]*100,2)`.  Like the decision tree model the random forest is better at accurately classify target values of 1.  In the above graph the green line shows the error on the TARGET value of 1, the red line shows the error of classify Target value of 0 and the black line shows the Out of bag error of the random forest.  From the chart it looks like the error has converged at around 200 trees, but it does look like it is starting to coverge again around 400 trees. What would happen if we were to add more trees?

### Find Optimal Tree

```{r, message=FALSE,warning=FALSE,tidy=TRUE}
control <- trainControl(method="repeatedcv", number=10, repeats=3, search="grid")

modellist <- list()
# loop to iterate through random forest models with different number of trees
for (ntree in c(200,1000, 1500, 2000)) {
fit <- train(factor(TARGET)~., data=train_data, method="rf", metric="Accuracy", tuneGrid=tunegrid,tuneLength = 50, trControl=control, ntree=ntree)
key <- toString(ntree)
modellist[[key]] <- fit
}
# compare results of all models (1000,1500 and 2000 trees)
results <- resamples(modellist)
summary(results)

# Predict Test results 100 Trees
RF200_model.pred <- predict(modellist$`200`, test_data)

# Check Accuracy of Model 
RF200_confus <- confusionMatrix(factor(RF200_model.pred),factor(test_data$TARGET))

# Predict Test results 1000 Trees
RF1000_model.pred <- predict(modellist$`1000`, test_data)

# Check Accuracy of Model 
RF1000_confus <- confusionMatrix(factor(RF1000_model.pred),factor(test_data$TARGET))

# Predict Test results 1500 Trees
RF2000_model.pred <- predict(modellist$`2000`, test_data)

# Check Accuracy of Model 
RF2000_confus <- confusionMatrix(factor(RF2000_model.pred),factor(test_data$TARGET))

# Predict Test results 2000 Trees
RF1500_model.pred <- predict(modellist$`1500`, test_data)

# Check Accuracy of Model 
RF1500_confus <- confusionMatrix(factor(RF1500_model.pred),factor(test_data$TARGET))

#Compare accuracy across all models created
pred_table <- data.table(Model = c("Decision Tree","Random Forest 200 Trees","Random Forest 500 Trees","Random Forest 1000 Tress","Random Forest 1500 Trees","Random Forest 2000 Trees"),Accuracy = c(confus$overall[1],RF200_confus$overall[1],RF_confus$overall[1],RF1000_confus$overall[1],RF1500_confus$overall[1],RF2000_confus$overall[1]))

pred_table

```

We ran the Random forest (RF) model with 200, 1000, 1500 and 2000 trees and compared there accuracy to our RF model with 500 trees and the Decision tree model. We can see the best model was the random forest with 1500 trees. This had an accuracy of `r round(RF1500_confus$overall[1]*100,2)`


# Evaluation

In summary, we have tried various models and tuning parameters and below summarizes the prediction accuracies:

Model         | Prediction Accuracy
--------------|---------------------
Decision Tree | 73.8%
RF 200        | 80.8%
RF 500        | 80.3%
RF 1000       | 80.3%
RF 1500       | 80.9%
RF 2000       | 80.3%

From the results above, we have the following observations:

* The random forest model is superior to the decision tree model as it is an ensemble model.
* For random forest, the errors converge fairly quickly starting at 100 trees. So the accuracy didn't improve further with the number of trees greater than 100. 

We reckon that 80% of prediction accuracy would provide a good foundation for further studies with the goal to use the model for clinical studies.

Futhermore, we found that the top 3 important measurements which could determine the heart disease diagnosis is as follows:

* THALACH (Maximum Heart Rate Achieved)
* EXANG (Exercise Induced Angina)
* OLDPEAK (ST Depression Induced by Exercise Relative to Rest)

Based on these findings, we will recommend Peter Munk to allocate more budget to improve the facilities and apparatus which are used to measure these attributes.

##Next Steps

The next step would be to try and acquire more data to train the model on.  Another step would be to try other classification models that do not use decision trees.  We could try Support Vector machines or Logistic Regression.


# Deployment

Given we have a model with fairly accurate prediction, we will deploy the model for the doctors to perform trial runs and receive feedback. 
