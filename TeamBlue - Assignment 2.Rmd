---
title: "Clustering Algorithm for Unupervised Learning - Credit Card Client Anomaly Analysis"
author: "Tyler Blakeley, Benjamin Kan, Mohammad Islam, Avijeet Singh"
date: "October 29 2018"
output:
  html_document:
    fig_height: 4.5
    fig_width: 7
    highlight: tango
    number_sections: yes
    theme: readable
    toc: yes
  pdf_document:
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
```
# Business Understanding
We work at the Retail Credit Risk Analytics department at the Bank of Taiwan. Recently, there have been increasing credit card debt defaults in our bank. Senior Management would like our department to develop a machine learning algorithm to find anomalies in the data that we hope will show early warning signs of default. This will allow the Retail Credit Risk and Collections departments to act early by reducing these cleints' credit card limits to minimize the losses. We would also like to find out which demographics are in the anomaly group which would indicate high susceptiblility of defaults. The Management instructed us to use data from the third parties to build the algorithms as proof-of-concepts before we use our own data. They would also like us to build a user-friendly app to allow them to load in the dataset and identify clients that are in the anomaly group which may indicate high risk of defaulting on their credit card debts.        

# Data Understanding

## Data Source and Collection
We sourced the third party credit card data from Kaggle (https://www.kaggle.com/uciml/default-of-credit-card-clients-dataset). This dataset contains information on default payments, demographic factors, credit data, history of payment, and bill statements of credit card clients in Taiwan from April 2005 to September 2005. As mentioned above, the goal is to identify a group of customers who exhibit abnormal behaviour comparing with the rest of the data. We assume that abnormal credit behaviour would lead to high default risks.

## Data Description
In the dataset, there are 25 variables:

Variable Name              | Description
---------------------------|--------------------------------------------------------------------------------
ID                         | ID of each client
LIMIT_BAL                  | Amount of given credit in NT dollars (includes individual and                                               | family/supplementary credit
SEX                        | Gender (1=male, 2=female)
EDUCATION                  | (1=graduate school, 2=university, 3=high school, 4=others, 5=unknown, 6=unknown)
MARRIAGE                   | Marital status (1=married, 2=single, 3=others)
AGE                        | Age in years
PAY_0                      | Repayment status in September, 2005 (-1=pay duly, 1=payment delay for one month,                            | 2=payment delay for two months, ... 8=payment delay for eight months, 9=payment                             | delay for nine months and above)                 
PAY_2                      | Repayment status in August, 2005 (scale same as above)
PAY_3                      | Repayment status in July, 2005 (scale same as above)
PAY_4                      | Repayment status in June, 2005 (scale same as above)
PAY_5                      | Repayment status in May, 2005 (scale same as above)
PAY_6                      | Repayment status in April, 2005 (scale same as above)
BILL_AMT1                  | Amount of bill statement in September, 2005 (NT dollar)
BILL_AMT2                  | Amount of bill statement in August, 2005 (NT dollar)
BILL_AMT3                  | Amount of bill statement in July, 2005 (NT dollar)
BILL_AMT4                  | Amount of bill statement in June, 2005 (NT dollar)
BILL_AMT5                  | Amount of bill statement in May, 2005 (NT dollar)
BILL_AMT6                  | Amount of bill statement in April, 2005 (NT dollar)
PAY_AMT1                   | Amount of previous payment in September, 2005 (NT dollar)
PAY_AMT2                   | Amount of previous payment in August, 2005 (NT dollar)
PAY_AMT3                   | Amount of previous payment in July, 2005 (NT dollar)
PAY_AMT4                   | Amount of previous payment in June, 2005 (NT dollar)
PAY_AMT5                   | Amount of previous payment in May, 2005 (NT dollar)
PAY_AMT6                   | Amount of previous payment in April, 2005 (NT dollar)
default.payment.next.month | Default payment (1=yes, 0=no)

## Data Exploration

### Load Packages
```{r, message=FALSE,warning=FALSE}
#import packages;
library(dplyr)
library(reshape2)
library(ggplot2)
library(Hmisc)
library(corrplot)
library(mice)
library(VIM)
library(pROC)
library(caret)
library(corrgram)
library(GGally)
library(ggthemes) 
library(DMwR)
library(gridExtra)
library(rattle)
library(readxl)
library(cluster)
```
### Load Datasets
Now that the packages are loaded, we can load in the dataset.

```{r, message=FALSE}
data <- read.csv("default of credit card clients.csv", header = TRUE, na= 'NA')
```

Now lets look at the structure of the data.

```{r, message=FALSE}
str(data)
```

##### AVI to RENAME THE FACTORS HERE #####

We note that all of the variables are numeric initially. We will need to convert certain variables into factors.

### Factor Categorical Variables and Create Unlabelled Dataset


```{r, message=FALSE,warning=FALSE}

#remove default column, create unlabelled dataset and ID Column
data <- data[,!colnames(data) %in% c("default.payment.next.month")]


#factor categorical variables
factor_VARS <- c('SEX','EDUCATION','MARRIAGE','PAY_0','PAY_2','PAY_3','PAY_4','PAY_5','PAY_6')

data[factor_VARS]<- lapply(data[factor_VARS],function(x) as.factor(x))

str(data)

```
Now we have appropriate variables that are converted into factors and the last column has been removed to make the dataset unlabelled. 

###Data Analysis
Now we explore the data. We can divide it into two categories:
* Univariate Exploration
* Bivariate Exploration

####Univariate exploration
We can further divide this into two categories for data exploration:
* Categorical Features
* Numerical Features

#####Categorical Features
Let us visualize the categorical data.

######SEX,EDUCATION,MARRIAGE
```{r, message=FALSE,warning=FALSE}
p1 = ggplot(data,aes(data$SEX))+geom_bar(fill="steelblue")+scale_x_discrete("Sex")+scale_y_continuous("No. of Observations")
p2 = ggplot(data,aes(data$EDUCATION))+geom_bar(fill="steelblue")+scale_x_discrete("Education")+scale_y_continuous("No. of Observations")
p3 = ggplot(data,aes(data$MARRIAGE))+geom_bar(fill="steelblue")+scale_x_discrete("Marriage")+scale_y_continuous("No. of Observations")
grid.arrange(p1,p2,p3,nrow = 1)
```

From the above graphs we made the following observations:
1. The number of females are more in the dataset as compared to number of males.
2. There are some values at "0" for the attributes Education and Marriage.
3. For education level, 5 and 6 are categorized as unknown so we can look into grouping them into one level.

######Pay Status
According to the description, PAY_x is a set of categorical variables with the levels:
  -1=pay duly, 1=payment delay for one month, 2=payment delay for two months,...8= payment delay for 8 months and 9=payment delay for 9 months and above.
```{r, message=FALSE,warning=FALSE}
p4 = ggplot(data,aes(data$PAY_0))+geom_bar(fill="steelblue")+scale_x_discrete("Payment Status Sept_2005")+scale_y_continuous("No. of Observations")
p5 = ggplot(data,aes(data$PAY_2))+geom_bar(fill="steelblue")+scale_x_discrete("Payment Status Aug_2005")+scale_y_continuous("No. of Observations")
p6 = ggplot(data,aes(data$PAY_3))+geom_bar(fill="steelblue")+scale_x_discrete("Payment Status July_2005")+scale_y_continuous("No. of Observations")
p7 = ggplot(data,aes(data$PAY_4))+geom_bar(fill="steelblue")+scale_x_discrete("Payment Status June_2005")+scale_y_continuous("No. of Observations")
p8 = ggplot(data,aes(data$PAY_5))+geom_bar(fill="steelblue")+scale_x_discrete("Payment Status May_2005")+scale_y_continuous("No. of Observations")
p9 = ggplot(data,aes(data$PAY_6))+geom_bar(fill="steelblue")+scale_x_discrete("Payment Status April_2005")+scale_y_continuous("No. of Observations")
grid.arrange(p4,p5,p6,p7,p8,p9,nrow = 2)
```

From the above graphs we made the following observation(s):
We observed undocumented values for the PAY attributes i.e "0" &"-2"
We went back to Kaggle and searched for related discussions in the forum and we found that these values have the following meaning.
* -2 = No consumption
* 0  = The use of revolving credit card.
Source: https://www.kaggle.com/uciml/default-of-credit-card-clients-dataset/discussion/34608 

So from here we found out that there are high number of observations where people are using revolving credit card. We also observed that there is a spike in payment delays in September 2005.

#####Numerical Features

We would like to know the distribution of the numerical variables:

######Age
```{r, message=FALSE,warning=FALSE}
p10 = ggplot(data, aes(data$AGE)) + geom_histogram(binwidth = 1,colour="black",fill="white")+  scale_x_continuous("Age")+scale_y_continuous("Observations Count")+labs(title = "Histogram")
p11 = ggplot(data, aes(,data$AGE)) + geom_boxplot(fill = "white")+  scale_y_continuous("Age")+scale_x_continuous("")+labs(title="Boxplot")
grid.arrange(p10,p11,nrow =1,top="AGE DISTRIBUTION AND OUTLIERS" )
```

As we can see above, the use of credit cards concentrates on younger age (< 40) with the average age of `r mean(data$AGE)`. 

######Limit of Balance
Lets explore the distribution and the outliers for the limit of balance.
```{r, message=FALSE,warning=FALSE}
ggplot(data, aes(data$LIMIT_BAL)) + geom_histogram(binwidth = 5000,colour="black",fill="white")+  scale_x_continuous("Limit_BAL")+scale_y_continuous("Obs.")+labs(title = "Histogram")
```

So we can see from the above histogram the people usually have the following limit balances: 20K, 30K, 50K, 80K, 200K and 500K.

Now lets us check for outliers with a boxplot.

```{r, message=FALSE,warning=FALSE}
ggplot(data, aes(x=factor(0),y=data$LIMIT_BAL)) + geom_boxplot(fill = "white")+
  scale_y_continuous("Limit_Bal")+scale_x_discrete("")+labs(title="Boxplot")
```

So we can see that the 75th percentile has the credit limit of 250K. Next we would like to know how many customers have extremely high credit limits. We set 600K as the threshold based on the boxplot above.


```{r, message=FALSE,warning=FALSE}
LIMIT_BAL_OUT <- with(data, which(LIMIT_BAL > 600000))
NROW(LIMIT_BAL_OUT)
```

As we can see, it is only 79 instances and we can consider removing these.

######Bill Amount
Lets explore the distribution and the outliers for BILL_AMTX. The document describes these attributes as follows:
  
BILL_AMT1                  | Amount of bill statement in September, 2005 (NT dollar)
BILL_AMT2                  | Amount of bill statement in August, 2005 (NT dollar)
BILL_AMT3                  | Amount of bill statement in July, 2005 (NT dollar)
BILL_AMT4                  | Amount of bill statement in June, 2005 (NT dollar)
BILL_AMT5                  | Amount of bill statement in May, 2005 (NT dollar)
BILL_AMT6                  | Amount of bill statement in April, 2005 (NT dollar)

```{r, message=FALSE,warning=FALSE}
p12 = ggplot(data, aes(data$BILL_AMT1)) + geom_histogram(binwidth = 5000,colour="black",fill="white")+  scale_x_continuous("BILL_AMT1")+scale_y_continuous("Obs.")+labs(title = "Sept_2005")
p13 = ggplot(data, aes(data$BILL_AMT2)) + geom_histogram(binwidth = 5000,colour="black",fill="white")+  scale_x_continuous("BILL_AMT2")+scale_y_continuous("Obs.")+labs(title = "Aug_2005")
p14 = ggplot(data, aes(data$BILL_AMT3)) + geom_histogram(binwidth = 5000,colour="black",fill="white")+  scale_x_continuous("BILL_AMT3")+scale_y_continuous("Obs.")+labs(title = "July_2005")
p15 = ggplot(data, aes(data$BILL_AMT4)) + geom_histogram(binwidth = 5000,colour="black",fill="white")+  scale_x_continuous("BILL_AMT4")+scale_y_continuous("Obs.")+labs(title = "June_2005")
p16 = ggplot(data, aes(data$BILL_AMT5)) + geom_histogram(binwidth = 5000,colour="black",fill="white")+  scale_x_continuous("BILL_AMT5")+scale_y_continuous("Obs.")+labs(title = "May_2005")
p17 = ggplot(data, aes(data$BILL_AMT6)) + geom_histogram(binwidth = 5000,colour="black",fill="white")+  scale_x_continuous("BILL_AMT6")+scale_y_continuous("Obs.")+labs(title = "April_2005")
grid.arrange(p12,p13,p14,p15,p16,p17,nrow =3,top="BILL_AMTX DISTRIBUTION" )

```

Now we have seen the distribution, lets check for outliers:
```{r, message=FALSE,warning=FALSE}
p18 = ggplot(data, aes(,data$BILL_AMT1)) + geom_boxplot(fill = "white")+  scale_y_continuous("BILL_AMT1")+scale_x_continuous("")+labs(title="Sept_2005")
p19 = ggplot(data, aes(,data$BILL_AMT2)) + geom_boxplot(fill = "white")+  scale_y_continuous("BILL_AMT2")+scale_x_continuous("")+labs(title="Aug_2005")
p20 = ggplot(data, aes(,data$BILL_AMT3)) + geom_boxplot(fill = "white")+  scale_y_continuous("BILL_AMT3")+scale_x_continuous("")+labs(title="July_2005")
p21 = ggplot(data, aes(,data$BILL_AMT4)) + geom_boxplot(fill = "white")+  scale_y_continuous("BILL_AMT4")+scale_x_continuous("")+labs(title="June_2005")
p22 = ggplot(data, aes(,data$BILL_AMT5)) + geom_boxplot(fill = "white")+  scale_y_continuous("BILL_AMT5")+scale_x_continuous("")+labs(title="May_2005")
p23 = ggplot(data, aes(,data$BILL_AMT6)) + geom_boxplot(fill = "white")+  scale_y_continuous("BILL_AMT6")+scale_x_continuous("")+labs(title="April_2005")
grid.arrange(p18,p19,p20,p21,p22,p23,nrow =3,top="OUTLIERS for BILL_AMTX" )
```


######Pay Amount
Lets explore the distribution and the outliers for PAY_AMTX. The document describes these attributes as follows:
  
PAY_AMT1                   | Amount of previous payment in September, 2005 (NT dollar)
PAY_AMT2                   | Amount of previous payment in August, 2005 (NT dollar)
PAY_AMT3                   | Amount of previous payment in July, 2005 (NT dollar)
PAY_AMT4                   | Amount of previous payment in June, 2005 (NT dollar)
PAY_AMT5                   | Amount of previous payment in May, 2005 (NT dollar)
PAY_AMT6                   | Amount of previous payment in April, 2005 (NT dollar)

```{r, message=FALSE,warning=FALSE}
p24 = ggplot(data, aes(data$PAY_AMT1)) + geom_histogram(binwidth = 5000,colour="black",fill="white")+  scale_x_continuous("PAY_AMT1")+scale_y_continuous("Obs.")+labs(title = "Histogram")
p25 = ggplot(data, aes(data$PAY_AMT2)) + geom_histogram(binwidth = 5000,colour="black",fill="white")+  scale_x_continuous("PAY_AMT2")+scale_y_continuous("Obs.")+labs(title = "Histogram")
p26 = ggplot(data, aes(data$PAY_AMT3)) + geom_histogram(binwidth = 5000,colour="black",fill="white")+  scale_x_continuous("PAY_AMT3")+scale_y_continuous("Obs.")+labs(title = "Histogram")
p27 = ggplot(data, aes(data$PAY_AMT4)) + geom_histogram(binwidth = 5000,colour="black",fill="white")+  scale_x_continuous("PAY_AMT4")+scale_y_continuous("Obs.")+labs(title = "Histogram")
p28 = ggplot(data, aes(data$PAY_AMT5)) + geom_histogram(binwidth = 5000,colour="black",fill="white")+  scale_x_continuous("PAY_AMT5")+scale_y_continuous("Obs.")+labs(title = "Histogram")
p29 = ggplot(data, aes(data$PAY_AMT6)) + geom_histogram(binwidth = 5000,colour="black",fill="white")+  scale_x_continuous("PAY_AMT6")+scale_y_continuous("Obs.")+labs(title = "Histogram")
grid.arrange(p24,p25,p26,p27,p28,p29,nrow =3,top="PAY_AMTX DISTRIBUTION" )

```

Now we have seen the distribution, lets check for outliers:
  
```{r, message=FALSE,warning=FALSE}
p30 = ggplot(data, aes(,data$PAY_AMT1)) + geom_boxplot(fill = "white")+  scale_y_continuous("PAY_AMT1")+scale_x_continuous("")+labs(title="Boxplot")
p31 = ggplot(data, aes(,data$PAY_AMT2)) + geom_boxplot(fill = "white")+  scale_y_continuous("PAY_AMT2")+scale_x_continuous("")+labs(title="Boxplot")
p32 = ggplot(data, aes(,data$PAY_AMT3)) + geom_boxplot(fill = "white")+  scale_y_continuous("PAY_AMT3")+scale_x_continuous("")+labs(title="Boxplot")
p33 = ggplot(data, aes(,data$PAY_AMT4)) + geom_boxplot(fill = "white")+  scale_y_continuous("PAYL_AMT4")+scale_x_continuous("")+labs(title="Boxplot")
p34 = ggplot(data, aes(,data$PAY_AMT5)) + geom_boxplot(fill = "white")+  scale_y_continuous("PAY_AMT5")+scale_x_continuous("")+labs(title="Boxplot")
p35 = ggplot(data, aes(,data$PAY_AMT6)) + geom_boxplot(fill = "white")+  scale_y_continuous("PAY_AMT6")+scale_x_continuous("")+labs(title="Boxplot")
grid.arrange(p30,p31,p32,p33,p34,p35,nrow =3,top="OUTLIERS for PAY_AMTX" )

```


####Bivariate Exploration

Let us now try to plot the relationship between two attributes from the dataset. Here we will just plot September 2005 data.

First, we would like to see if there is any relationship between age and credit limits:

```{r, message=FALSE,warning=FALSE}
ggplot(data, aes(AGE, LIMIT_BAL)) + geom_point() +
  scale_x_continuous("Age", breaks = seq(0,60,20))+
  scale_y_continuous("Limit_Bal", breaks = seq(0,1000000,by = 50000))+ theme_bw()

library(ggpubr)
ggscatter(data, x = "AGE", y = "LIMIT_BAL",
         add = "reg.line", conf.int = TRUE,
         cor.coef = TRUE, cor.method = "pearson",
         xlab = "Age", ylab = "Limit_Bal")

```

According to the graph above, there is little relationship between age and credit limits.


Let us take a look at the relationship between marriage status and re-payment status as of September 2005:
  
```{r, message=FALSE,warning=FALSE}
ggplot(data,aes(x=PAY_0,fill = MARRIAGE))+geom_bar(position = "fill")
```
So it looks like the single people tend to delay the re-payment more than the married people do, with some exceptions.

Now lets check if there is any trend we can observe if we plot the repayment status w.r.t sex.
We will start with PAY_0 i.e The repayment status in september just to see if we see a trend and then we can explore further.

```{r, message=FALSE,warning=FALSE}
ggplot(data,aes(x=PAY_0,fill = SEX))+geom_bar(position = "fill")
```

Looks like more number of females paid the amount duly in september and more number of males had a delay in re-payment.
Let us check for the rest of the months to see if it is the same situation every month.
```{r, message=FALSE,warning=FALSE}
b1 = ggplot(data,aes(x=PAY_2,fill = SEX))+geom_bar(position = "fill")
b2 = ggplot(data,aes(x=PAY_3,fill = SEX))+geom_bar(position = "fill")
b3 = ggplot(data,aes(x=PAY_4,fill = SEX))+geom_bar(position = "fill")
b4 = ggplot(data,aes(x=PAY_5,fill = SEX))+geom_bar(position = "fill")
b5 = ggplot(data,aes(x=PAY_6,fill = SEX))+geom_bar(position = "fill")
grid.arrange(b1,b2,b3,b4,b5,nrow = 3)
```

Just as we suspected! The males are more likely to delay the repayment as compared to the females.

# Modelling

## Select Modelling Technique

We chose to start with a k means clustering alorgirthm as most of our data was numeric. The first step to running the alogirthm is to make all the categorical variables into numeric by encoding them.  We chose to implement one hot encoding because our variables are nominal and not ordinal. 

## Encode Data

```{r, message=FALSE,warning=FALSE}
set.seed(456292)



#encod categorical columns
dummies_model <- dummyVars(ï..ID ~ ., data=data)

# Create the dummy variables using predict. The Y variable (ï..ID) will not be present in encod
encod <- predict(dummies_model, newdata = data)

# # Convert to dataframe
data_encoded <- data.frame(encod)

# # Summary of the new dataset
summary(data_encoded)



```

Now that the data is encoded and all variables are numeric we can implement the K means algorithm.  The K means algorithm works by creating K cluster.  Each cluster is based on feature similarity.  The alogirthm starts by randomly picking K centroids, then the alogirthm iterates through each point and assigns it to the nearest cluster based a distance formula. (ex: Euclidean).  After each point as been assigned a cluster, the centroids are re calculated by taking the mean of all data points in the clusters, next the points are reclassifed again until a stopping criteria is met. (No points change clusters or the mean of all data points in the cluster is minimized.)


## Scale the Data

Since the K means algorithm using distance to find the nearest point we need to ensure all the variables are on the same range.  We do this by normalizing the data.

```{r, message=FALSE,warning=FALSE}

normalize = function(x) {
  return ((x - min(x)) / (max(x) - min(x)))
}

df = as.data.frame(lapply(df, normalize))


```

## Find Optimal number of Clusters (K)

Before we run the K Mean algorithm we need to find the optimal K clusters. To find the optimal number of clusters we used the Elbow method. The elbow method finds the optinal K value by running mulptiple K Means for K from 1 to N and calculateing the Sum of Squared errors (SSE).  We then plot each SSE for each K, we then chose the smallest K such that it has a low SSE which is at the elbow point of the plot.

```{r, message=FALSE,warning=FALSE}
#Find Optimal K using Elbow method

df <- sample_n(data_encoded,30000)

wssplot <- function(data, nc=15, seed=1234){
  wss <- (nrow(data)-1)*sum(apply(data,2,var))
  for (i in 2:nc){
    set.seed(seed)
    wss[i] <- sum(kmeans(data, centers=i)$withinss)}
  plot(1:nc, wss, type="b", xlab="Number of Clusters",
       ylab="Within groups sum of squares")}

wssplot(df, nc=10) 



```

Based on the Elbow method, we found the optinal number to be 6


## Build K Means Model 

We are now able to create the K mean model, we are creating K = 6 clusters, we also use nstart = 5 to run the k means algorithm 5 times with random centroids each time and take the best result.

```{r, message=FALSE,warning=FALSE}

kmeans.result <- kmeans(df, centers=6,nstart = 5)

```

Explain K Means Models ......


## Assess Clusters

```{r, message=FALSE,warning=FALSE}


#Describe Clusters

#ClusterSize
kmeans.result$size

#Cluster Center Attributes 
kmeans.result$centers


#Vizualize Clusters
par(mfrow=c(3,2))


```


### Visualize Model with PCA

We will use Principle Componet Analysis (PCA) to help us Visualize our clusters.  PCA works by reducing dimensoinality of the data. We want to reduce the dimensionality to 2d because it will allow us to graph the clusters. PCA 
creates new columns that are linearly uncorrelated variables, and sorts thems in descending where PC1 will account for the highest variability of the data, and PC2 will be seocnd most and so on.

```{r, message=FALSE,warning=FALSE}
df_pca <- prcomp(df)
df_out <- as.data.frame(df_pca$x)

p<-ggplot(df_out,aes(x=PC1,y=PC2,color = as.factor(kmeans.result$cluster ) ))
theme<-theme(panel.background = element_blank(),panel.border=element_rect(fill=NA),panel.grid.major = element_blank(),panel.grid.minor = element_blank(),strip.background=element_blank(),axis.text.x=element_text(colour="black"),axis.text.y=element_text(colour="black"),axis.ticks=element_line(colour="black"),plot.margin=unit(c(1,1,1,1),"line"))
percentage <- round(df_pca$sdev / sum(df_pca$sdev) * 100, 2)
percentage <- paste( colnames(df_out), "(", paste( as.character(percentage), "%", ")", sep="") )

p<-p+geom_point()+theme+xlab(percentage[1]) + ylab(percentage[2])

p

```

Looking at the vizualized data we can see the clusters are well formed and there is minimal overlap, the dclusters are almost fully homogeneous.


##Find Anomalies (Outliers)



###Anomaly Detection using K Means

```{r, message=FALSE, warning=FALSE}

#Find the Center of each cluster
centers <- kmeans.result$centers[kmeans.result$cluster, ]  

# Calculate distance each point is from the center of the cluster
distances <- sqrt(rowSums((df - centers)^2))
# Take the top 20 fartherest points from the cluster center
outliers <- order(distances, decreasing=T)[1:20]

#Plot Outliers
p<-p + geom_point(data=df_out[outliers,],aes(x=PC1,y=PC2), colour="red", size=4)+ggtitle("PCA 6 Means Cluster with Outliers")

p



```



###Anomaly Detection using Local Outlier Factor


Another way to find outlier in unsupervised learning is by using the Local outlier
Facotr alogorithm.  This alogrithm is similar to the previous one we used but differs
by comparing local density,where locality is based on the k nearest neighbours.  The LOF
allows us to identify outliers in a data set tha would not be outliers in another area of the data set.


```{r, message=FALSE,warning=FALSE}

#run LOF Model takes awhile 5 to 10 minutes
outlier.scores <- lofactor(df,k=30)

#Plotdensity of Outliers
plot(density(outlier.scores))


#Plot outliers from LOF
outliers_lof <- order(outlier.scores, decreasing=T)[1:20]


p_lof<-ggplot(df_out,aes(x=PC1,y=PC2,color = as.factor(kmeans.result$cluster ) ))+geom_point()+theme+xlab(percentage[1]) + ylab(percentage[2]) + geom_point(data=df_out[outliers_lof,],aes(x=PC1,y=PC2), colour="red", size=3)+ggtitle("PCA LOF Outliers")


#compare K means outlier to LOF
grid.arrange(p, p_lof, nrow = 2,ncol = 1)



```







### Look at individual outliers

```{r, message=FALSE,warning=FALSE}


```


# Evaluation

In summary, we have tried various models and tuning parameters and below summarizes the prediction accuracies:

Model         | Prediction Accuracy
--------------|---------------------
Decision Tree | 73.8%
RF 200        | 80.8%
RF 500        | 80.3%
RF 1000       | 80.3%
RF 1500       | 80.9%
RF 2000       | 80.3%

From the results above, we have the following observations:

* The random forest model is superior to the decision tree model as it is an ensemble model.
* For random forest, the errors converge fairly quickly starting at 100 trees. So the accuracy didn't improve further with the number of trees greater than 100. 

We reckon that 80% of prediction accuracy would provide a good foundation for further studies with the goal to use the model for clinical studies.

Futhermore, we found that the top 3 important measurements which could determine the heart disease diagnosis is as follows:

* THALACH (Maximum Heart Rate Achieved)
* EXANG (Exercise Induced Angina)
* OLDPEAK (ST Depression Induced by Exercise Relative to Rest)

Based on these findings, we will recommend Peter Munk to allocate more budget to improve the facilities and apparatus which are used to measure these attributes.

##Next Steps

The next step would be to try and acquire more data to train the model on.  Another step would be to try other classification models that do not use decision trees.  We could try Support Vector machines or Logistic Regression.


# Deployment

Given we have a model with fairly accurate prediction, we will deploy the model for the doctors to perform trial runs and receive feedback. 
